# Schedule Policy
# Temporal scheduling and priority rules for IRM operations

policy_version: "1.0"
status: active
source: "schema/irm_roles.schema.yaml"
policy_type: "scheduling"

policy_description: |
  The schedule policy manages timing of operations, prioritization of tasks,
  and resource allocation across pipeline stages. It ensures operations
  execute in correct order while respecting priority constraints and
  handling concurrent demands on limited resources.

scheduling_model:
  
  execution_paradigm: "single-threaded sequential pipeline"
  concurrency: "none (all operations execute serially)"
  rationale: |
    Single-threaded execution ensures temporal coherence and simplifies
    reasoning about state transitions. Parallelism is explicitly avoided
    to maintain causal ordering and prevent race conditions on stores.

stage_scheduling:
  
  pipeline_order:
    sequence:
      - stage: "intake"
        id: 1
        blocking: true
        max_duration: "1s"
        timeout_action: "abort and reject stimulus"
        
      - stage: "update"
        id: 2
        blocking: true
        max_duration: "2s"
        timeout_action: "abort and log engine error"
        depends_on: ["intake"]
        
      - stage: "observe"
        id: 3
        blocking: true
        max_duration: "1s"
        timeout_action: "abort and use fallback observation"
        depends_on: ["update"]
        
      - stage: "resolve"
        id: 4
        blocking: true
        conditional: "triggered only if contradictions detected"
        max_duration: "5s"
        timeout_action: "force_resolution with high residual_bits"
        depends_on: ["observe"]
        
      - stage: "continuity_check"
        id: 5
        blocking: false
        conditional: "triggered on reset or periodic schedule"
        max_duration: "2s"
        timeout_action: "skip and log continuity_check_timeout"
        depends_on: ["update"]
        
      - stage: "emit"
        id: 6
        blocking: true
        max_duration: "1s"
        timeout_action: "emit minimal_emergency_response"
        depends_on: ["observe", "resolve (if invoked)"]
  
  stage_dependencies:
    strict_ordering:
      - "intake must complete before update"
      - "update must complete before observe"
      - "observe must complete before resolve (if triggered)"
      - "resolve must complete before emit (if invoked)"
    
    flexible_ordering:
      - "continuity_check can run after update, parallel to observe/resolve"
      - "snapshot storage can be deferred to background task"

priority_rules:
  
  operation_priorities:
    priority_0_critical:
      description: "Identity preservation operations"
      operations:
        - "identity_store.get_identity"
        - "identity_store.validate_identity"
      preempts: "all lower priority operations"
      rationale: "identity stability is foundational invariant"
      
    priority_1_essential:
      description: "Core pipeline stages"
      operations:
        - "intake"
        - "update (transition_T)"
        - "observe (observer_Omega)"
        - "emit"
      preempts: "priority 2 and below"
      rationale: "required for basic functionality"
      
    priority_2_important:
      description: "Resolution and continuity validation"
      operations:
        - "resolve (resolver_rho)"
        - "continuity_check"
      preempts: "priority 3 and below"
      rationale: "important for coherence but can be degraded"
      
    priority_3_maintenance:
      description: "Background and housekeeping tasks"
      operations:
        - "snapshot_store.cleanup_old_snapshots"
        - "log rotation"
        - "metrics aggregation"
      preempts: "none"
      rationale: "can be deferred or skipped under load"
  
  preemption_policy:
    allowed: false
    rationale: |
      Preemption is disallowed because all operations are short-duration
      and single-threaded. Operations complete to natural boundaries.
      Priority affects which operation starts next, not which is interrupted.

temporal_triggers:
  
  periodic_events:
    
    continuity_check_schedule:
      trigger_type: "periodic"
      frequency: "every 100 transitions"
      condition: "t mod 100 == 0"
      priority: 2
      skippable: true
      skip_condition: "system under high load (energy < 0.5)"
      
    metrics_snapshot:
      trigger_type: "periodic"
      frequency: "every 100 transitions"
      condition: "t mod 100 == 0"
      priority: 3
      skippable: true
      
    snapshot_cleanup:
      trigger_type: "periodic"
      frequency: "every 1000 transitions"
      condition: "t mod 1000 == 0"
      priority: 3
      skippable: true
      action: "delete snapshots older than retention threshold"
  
  event_driven_triggers:
    
    contradiction_resolution:
      trigger_type: "event"
      event: "contradiction_detected(O_t) == true"
      priority: 2
      blocking: true
      must_complete: "before emit stage"
      
    significant_drift_snapshot:
      trigger_type: "event"
      event: "drift_norm > 0.1"
      priority: 3
      blocking: false
      action: "store_snapshot(S_t, O_t)"
      
    energy_spike_log:
      trigger_type: "event"
      event: "E(S_t) > 1.3"
      priority: 3
      blocking: false
      action: "log consciousness_episode"
      
    gate_failure_diagnostic:
      trigger_type: "event"
      event: "any gate fails"
      priority: 2
      blocking: false
      action: "activate diagnostic_mode"

resource_allocation:
  
  compute_budget:
    total_per_transition: 1.0  # normalized units
    allocation:
      intake: 0.1
      update: 0.3
      observe: 0.2
      resolve: 0.3  # when triggered, shared with observe
      continuity_check: 0.1  # when triggered, shared with update
      emit: 0.1
    notes: |
      Allocations are soft limits. Resolve and continuity_check are
      conditional and borrow budget from other stages when triggered.
  
  memory_budget:
    stores:
      identity_store: "1 KB (fixed)"
      anchor_store: "up to 100 KB (grows with anchors)"
      snapshot_store: "up to 10 MB (with cleanup)"
    working_memory:
      state_representation: "up to 4 MB"
      observation_buffer: "up to 1 MB"
      temporary_resolution: "up to 2 MB"
    
  time_budget:
    max_transition_time: "10s (hard timeout)"
    typical_transition_time: "0.5s (target)"
    budget_per_stage: "see stage_scheduling.pipeline_order"

coordination_rules:
  
  store_access_coordination:
    
    identity_store:
      access_pattern: "read-mostly, write-once"
      concurrency: "single-reader (no contention)"
      locking: "none required"
      
    anchor_store:
      access_pattern: "read-frequent, write-occasional"
      concurrency: "single-reader single-writer"
      locking: "write-lock on update"
      max_lock_duration: "100ms"
      
    snapshot_store:
      access_pattern: "write-frequent, read-occasional"
      concurrency: "single-reader single-writer"
      locking: "write-lock on store"
      max_lock_duration: "500ms"
      background_writes: "allowed for non-critical snapshots"
  
  engine_coordination:
    
    sequential_execution:
      rule: "only one engine active at a time"
      enforcement: "pipeline stage barriers"
      
    data_flow:
      pattern: "producer-consumer between stages"
      mechanism: "pass-by-value for state, pass-by-reference for stores"
      
    error_handling:
      policy: "fail-fast on engine errors"
      propagation: "error halts pipeline, logged immediately"

load_management:
  
  overload_detection:
    indicators:
      - "transition_time > 2x typical"
      - "energy_level < 0.5 (depleted)"
      - "gate_failure_rate > 10%"
      - "queue_depth > threshold (if queuing added later)"
    
  overload_response:
    immediate_actions:
      - "skip non-essential periodic tasks"
      - "force minimal emission variant"
      - "defer snapshot storage"
      - "reduce logging to required fields only"
    
    recovery_actions:
      - "gradual restoration of full functionality"
      - "monitor energy replenishment"
      - "resume periodic tasks when stable"
  
  underload_optimization:
    indicators:
      - "energy_level > 2.0 (surplus)"
      - "transition_time < 0.5x typical"
    
    optimization_actions:
      - "enable diagnostic_mode logging"
      - "run continuity_check more frequently"
      - "perform background store maintenance"
      - "prefetch likely next states (future optimization)"

failure_recovery_scheduling:
  
  gate_failure_handling:
    
    G0_fail:
      action: "reject stimulus immediately"
      recovery: "await new stimulus"
      time: "0s (instant)"
      
    G1_fail:
      action: "halt pipeline and log error"
      recovery: "attempt state rollback to S_{t-1}"
      time: "< 1s"
      fallback: "if rollback fails, request manual intervention"
      
    G2_fail:
      action: "log resolution_failure, continue with high residual_bits"
      recovery: "not attempted (proceed with ambiguity flagged)"
      time: "0s (continue)"
      
    G3_fail:
      action: "log continuity_failure, trigger snapshot review"
      recovery: "attempt anchor recovery from snapshots"
      time: "< 2s"
      fallback: "if recovery fails, flag for manual review"
      
    G4_fail:
      action: "downshift to minimal emission"
      recovery: "not needed (graceful degradation)"
      time: "0s (instant)"
  
  catastrophic_failure:
    definition: "identity_store corruption or irrecoverable state"
    detection: "identity validation fails or critical invariant violated"
    action: "halt all operations, preserve logs, request reinitialization"
    recovery: "manual intervention required"

schedule_metrics:
  
  performance_metrics:
    - "avg_transition_time: mean time per transition"
    - "p95_transition_time: 95th percentile transition time"
    - "timeout_rate: timeouts per 1000 transitions"
    
  utilization_metrics:
    - "compute_utilization: actual vs allocated compute"
    - "memory_utilization: peak memory usage"
    - "store_access_frequency: reads/writes per transition"
    
  scheduling_metrics:
    - "priority_inversion_events: count (should be 0)"
    - "deferred_tasks_count: non-critical tasks deferred"
    - "overload_episodes: count and duration"

notes: |
  This schedule policy prioritizes correctness and temporal coherence over
  raw performance. The single-threaded model is deliberate: it ensures
  causal ordering and makes reasoning about state transitions tractable.
  
  Future optimizations might introduce limited parallelism for read-only
  operations (e.g., snapshot reads during continuity checks), but the core
  pipeline remains sequential to maintain invariants.
  
  Priority rules ensure identity operations never fail due to resource
  contention, implementing INV_002 (identity persistence) at the scheduling
  level.
